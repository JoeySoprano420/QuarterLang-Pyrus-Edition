# ruleset.qtr
# QuarterLang-Pyrus Edition Parsing and Lexing Ruleset
# -----------------------------------------------
# Defines tokens, keywords, grammar productions,
# indentation/nesting, data types, and semantic actions.
#
# Designed for use by the QuarterLang compiler frontend.
#
# Author: (Your Name)
# Version: 1.0
# Date: 2025-08-01
# -----------------------------------------------

# --- Lexer Tokens ---

TOKEN_STAR       = 'star'
TOKEN_END        = 'end'

# Keywords
TOKEN_VAL        = 'val'
TOKEN_VAR        = 'var'
TOKEN_DERIVE     = 'derive'
TOKEN_DG         = 'dg'
TOKEN_SAY        = 'say'
TOKEN_LOOP       = 'loop'
TOKEN_WHEN       = 'when'
TOKEN_ELSE       = 'else'
TOKEN_MATCH      = 'match'
TOKEN_CASE       = 'case'
TOKEN_DEFINE     = 'define'
TOKEN_PROCEDURE  = 'procedure'
TOKEN_RETURN     = 'return'
TOKEN_YIELD      = 'yield'
TOKEN_FN         = 'fn'
TOKEN_THREAD     = 'thread'
TOKEN_PIPE       = 'pipe'
TOKEN_NEST       = 'nest'
TOKEN_ASM        = 'asm'
TOKEN_STOP       = 'stop'

# Data types
TOKEN_INT        = 'int'
TOKEN_FLOAT      = 'float'
TOKEN_BOOL       = 'bool'
TOKEN_STRING     = 'string'
TOKEN_DG_TYPE    = 'dg'         # Dodecagram type suffix

# Literals
TOKEN_INT_LITERAL       = /-?\d+/
TOKEN_FLOAT_LITERAL     = /-?\d+\.\d+/
TOKEN_BOOL_LITERAL      = 'true' | 'false'
TOKEN_STRING_LITERAL    = /"([^"\\]|\\.)*"/

# Dodecagram literals: prefixed dg: or suffixed as dg type
TOKEN_DG_LITERAL        = /dg:[0-9A-B]+/i

# Identifiers (variable, function names)
TOKEN_IDENTIFIER        = /[a-zA-Z_][a-zA-Z0-9_]*/

# Operators & punctuation
TOKEN_COLON             = ':'
TOKEN_COMMA             = ','
TOKEN_LPAREN            = '('
TOKEN_RPAREN            = ')'
TOKEN_LBRACE            = '{'
TOKEN_RBRACE            = '}'
TOKEN_ARROW             = '->'
TOKEN_ASSIGN            = ':='
TOKEN_PLUS              = '+'
TOKEN_MINUS             = '-'
TOKEN_MULTIPLY          = '*'
TOKEN_DIVIDE            = '/'
TOKEN_GREATER           = '>'
TOKEN_LESS              = '<'
TOKEN_EQUAL             = '=='
TOKEN_NOT_EQUAL         = '!='

# Comments
TOKEN_COMMENT           = /#.*$/


# --- Grammar ---

START: program

program:
    TOKEN_STAR block_body TOKEN_END
    ;

block_body:
    statement*
    ;

statement:
      var_decl
    | val_decl
    | derive_stmt
    | say_stmt
    | loop_stmt
    | when_stmt
    | match_stmt
    | func_decl
    | procedure_decl
    | return_stmt
    | yield_stmt
    | fn_expr
    | thread_stmt
    | pipe_stmt
    | nest_stmt
    | asm_stmt
    | stop_stmt
    | expr_stmt
    ;

# Variable declarations
val_decl:
    TOKEN_VAL TOKEN_IDENTIFIER 'as' type TOKEN_COLON expr
    ;

var_decl:
    TOKEN_VAR TOKEN_IDENTIFIER 'as' type TOKEN_COLON expr
    ;

derive_stmt:
    TOKEN_DERIVE TOKEN_IDENTIFIER 'from' TOKEN_IDENTIFIER 'by' expr
    ;

say_stmt:
    TOKEN_SAY expr
    ;

loop_stmt:
    TOKEN_LOOP 'from' expr 'to' expr TOKEN_COLON block_body TOKEN_END?
    ;

when_stmt:
    TOKEN_WHEN expr TOKEN_COLON block_body (TOKEN_ELSE TOKEN_COLON block_body)?
    ;

match_stmt:
    TOKEN_MATCH expr TOKEN_COLON match_cases
    ;

match_cases:
    (case_stmt)+
    ;

case_stmt:
    TOKEN_CASE pattern TOKEN_COLON block_body
    ;

func_decl:
    TOKEN_DEFINE TOKEN_IDENTIFIER '(' param_list? ')' (':' type)? block_body TOKEN_END
    ;

procedure_decl:
    TOKEN_PROCEDURE TOKEN_IDENTIFIER '(' param_list? ')' block_body TOKEN_END
    ;

return_stmt:
    TOKEN_RETURN expr?
    ;

yield_stmt:
    TOKEN_YIELD expr
    ;

fn_expr:
    TOKEN_FN '(' param_list? ')' (':' type)? block_body TOKEN_END
    ;

thread_stmt:
    TOKEN_THREAD TOKEN_IDENTIFIER? '(' ')' block_body TOKEN_END
    ;

pipe_stmt:
    TOKEN_PIPE 'write:' expr
    ;

nest_stmt:
    TOKEN_NEST block_body TOKEN_END
    ;

asm_stmt:
    TOKEN_ASM '{' asm_body '}'
    ;

stop_stmt:
    TOKEN_STOP
    ;

expr_stmt:
    expr
    ;

param_list:
    param (TOKEN_COMMA param)*
    ;

param:
    TOKEN_IDENTIFIER 'as' type
    ;

type:
      TOKEN_INT
    | TOKEN_FLOAT
    | TOKEN_BOOL
    | TOKEN_STRING
    | TOKEN_DG_TYPE
    ;

pattern:
      TOKEN_INT_LITERAL
    | TOKEN_BOOL_LITERAL
    | TOKEN_IDENTIFIER
    | '(' pattern (TOKEN_COMMA pattern)* ')'
    ;

expr:
      literal
    | TOKEN_IDENTIFIER
    | expr binary_op expr
    | unary_op expr
    | '(' expr ')'
    | fn_expr
    ;

literal:
      TOKEN_INT_LITERAL
    | TOKEN_FLOAT_LITERAL
    | TOKEN_BOOL_LITERAL
    | TOKEN_STRING_LITERAL
    | TOKEN_DG_LITERAL
    ;

binary_op:
      TOKEN_PLUS
    | TOKEN_MINUS
    | TOKEN_MULTIPLY
    | TOKEN_DIVIDE
    | TOKEN_GREATER
    | TOKEN_LESS
    | TOKEN_EQUAL
    | TOKEN_NOT_EQUAL
    ;

unary_op:
      TOKEN_PLUS
    | TOKEN_MINUS
    ;

asm_body:
    /(.|\n)*?/
    ;

# --- Semantic & Structural Rules ---

# 1. Program must start with 'star' and end with 'end'.
# 2. Blocks opened by keywords (define, loop, match, etc.) must be explicitly closed.
# 3. Indentation is virtual and enforces nesting and scope.
# 4. Immutable variables declared by 'val' cannot be reassigned.
# 5. Mutable variables declared by 'var' can be reassigned.
# 6. Derive statements produce new variables by transforming existing ones.
# 7. DG literals and operations support base-12 numeric semantics.
# 8. Inline asm blocks accept raw NASM instructions.
# 9. Functions (define, procedure) support typed params and optional return types.
# 10. Control flow constructs (loop, when, match) have lexical scoping and nesting.
# 11. Threads run lightweight parallel tasks.
# 12. Pipe statement redirects output to external streams/files.
# 13. Stop immediately halts runtime execution.

# --- Notes on Virtual Indentation and Zoomed Spacing ---

# The parser frontend must implement a virtual indentation tracking system:
# - Increase indentation level after block openings (loop, define, when, etc.)
# - Decrease indentation on 'end' keyword or block close
# - Nesting must be strictly enforced; improper nesting triggers syntax errors

# --- Dodecagram (DG) Support ---

# DG literals must be parsed as base-12 numbers:
# - Digits 0-9 represent 0-9
# - 'A' = 10, 'B' = 11
# Conversion functions 'to_dg', 'from_dg', 'dg_add', 'dg_mul' are built-in.

# --- Example rule for dg literal parsing ---

DG_LITERAL_PATTERN = /dg:([0-9A-B]+)/i

# --- End of ruleset ---

<> --- Optimizations --- <>

# --- Compiler Optimization Guidelines & Rules ---

# Optimization Passes to Integrate into the QuarterLang-Pyrus Compilation Pipeline

optimization:
  - name: "Symbolic Constant Folding"
    description: |
      Precompute constant expressions at compile time, especially DG
      arithmetic like `dg:3A + dg:1B`. Reduces runtime computation overhead.
    benefit: "Reduces symbolic arithmetic overhead by 10-20%"
    enabled: true

  - name: "Capsule Pruning"
    description: |
      Remove redundant or unreachable instructions from emitted bytecode.
      Improves capsule size and runtime efficiency.
    benefit: "Shrinks bytecode size and improves cache locality by 5-15%"
    enabled: true

  - name: "Opcode Density Profiling"
    description: |
      Analyze execution traces to identify hotspots and
      optimize high-frequency opcode paths dynamically.
    benefit: "Targets high-frequency paths for tuning, improving performance 10-30%"
    enabled: true

  - name: "Entropy-Aware Execution"
    description: |
      Prioritize execution of low-entropy, predictable paths in capsules.
      Improves dispatch speed and enhances traceability.
    benefit: "Enhances dispatch predictability and opcode trace quality"
    enabled: true

  - name: "Inline Function Expansion"
    description: |
      Expand anonymous and small named functions (`fn`) inline
      at call sites to reduce function call overhead.
    benefit: "Reduces call overhead, especially in fn expressions by 5-20%"
    enabled: true

  - name: "Thread Scheduling Optimization"
    description: |
      Balance and schedule parallel threads efficiently across CPU cores.
      Dynamically adapt thread workload to optimize resource utilization.
    benefit: "Improves parallelism and resource utilization by 2×–4×"
    enabled: true

  - name: "DG Arithmetic Simplification"
    description: |
      Simplify symbolic DG arithmetic expressions before runtime
      using algebraic reduction rules for base-12 numbers.
    benefit: "Reduces runtime DG expression complexity and instruction count"
    enabled: true

  - name: "REPL Trace Caching"
    description: |
      Cache opcode execution traces during REPL sessions to
      accelerate debugging and interactive feedback loops.
    benefit: "Speeds up debugging cycles by reusing prior opcode traces"
    enabled: true

  - name: "Signature-Based Deduplication"
    description: |
      Detect identical capsules via cryptographic hashes/signatures
      and avoid recompilation or duplicate deployment.
    benefit: "Avoids recompiling identical capsules, saving build time and storage"
    enabled: true


# --- Performance Benchmark Expectations ---

performance_benchmarks:
  - optimization: "Symbolic Constant Folding"
    expected_gain: "10–20%"
    notes: "Precomputes DG expressions to reduce runtime cost"

  - optimization: "Capsule Pruning"
    expected_gain: "5–15%"
    notes: "Removes dead code, improves cache locality"

  - optimization: "Opcode Density Profiling"
    expected_gain: "10–30%"
    notes: "Enables hotspot-driven tuning"

  - optimization: "Inline Function Expansion"
    expected_gain: "5–20%"
    notes: "Inlines fn blocks to reduce call overhead"

  - optimization: "Thread Scheduling Optimization"
    expected_gain: "2×–4×"
    notes: "Balances workload to improve CPU core utilization"

  - optimization: "Entropy-Aware Execution"
    expected_gain: "Indirect"
    notes: "Improves dispatch predictability and trace overlays"


# --- Integration Notes ---

# These optimizations align with QuarterLang's symbolic, introspective,
# and capsule-centric philosophy. They enable:

# - Capsule health metrics tracking (entropy, memory usage)
# - Opcode trace overlays and visualization
# - Deterministic replay and rewind debugging
# - Aggressive static and dynamic code optimization

# The compiler's optimization pipeline should support toggling these passes,
# enable detailed logging for diagnostics, and interoperate with
# REPL and runtime monitoring tools.

# This completes the ruleset augmentation for compiler optimizations.

